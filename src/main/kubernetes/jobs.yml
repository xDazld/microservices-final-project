---
# Database Initialization Job
apiVersion: batch/v1
kind: Job
metadata:
  name: mariadb-init
  namespace: dns-filtering
  labels:
    app.kubernetes.io/name: mariadb
    app.kubernetes.io/component: database
    job.kubernetes.io/name: initialization
spec:
  activeDeadlineSeconds: 300
  backoffLimit: 3
  ttlSecondsAfterFinished: 3600
  template:
    metadata:
      labels:
        app.kubernetes.io/name: mariadb
        app.kubernetes.io/component: database
    spec:
      restartPolicy: OnFailure
      serviceAccountName: mariadb-account
      containers:
        - name: mariadb-init
          image: docker.io/library/mariadb:latest
          imagePullPolicy: Always
          command:
            - /bin/sh
            - -c
            - |
              echo "Waiting for MariaDB to be ready..."
              for i in {1..30}; do
                if mysqladmin ping -h mariadb -u root -p${MYSQL_ROOT_PASSWORD}; then
                  echo "MariaDB is ready"
                  exit 0
                fi
                echo "Attempt $i/30 - Waiting for MariaDB..."
                sleep 2
              done
              echo "MariaDB failed to start"
              exit 1
          env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mariadb-credentials
                  key: MYSQL_ROOT_PASSWORD
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 500m
              memory: 512Mi
---
# Kafka Topic Creation Job
apiVersion: batch/v1
kind: Job
metadata:
  name: kafka-topics-init
  namespace: dns-filtering
  labels:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/component: messaging
    job.kubernetes.io/name: initialization
spec:
  activeDeadlineSeconds: 300
  backoffLimit: 3
  ttlSecondsAfterFinished: 3600
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kafka
        app.kubernetes.io/component: messaging
    spec:
      restartPolicy: OnFailure
      serviceAccountName: kafka-account
      containers:
        - name: kafka-topics-init
          image: docker.io/redpandadata/redpanda:latest
          imagePullPolicy: Always
          command:
            - /bin/sh
            - -c
            - |
              echo "Waiting for Kafka to be ready..."
              for i in {1..30}; do
                if nc -z kafka 9092; then
                  echo "Kafka is ready"
                  exit 0
                fi
                echo "Attempt $i/30 - Waiting for Kafka..."
                sleep 2
              done
              echo "Kafka failed to start"
              exit 1
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 500m
              memory: 512Mi
---
# Daily Health Check Job
apiVersion: batch/v1
kind: Job
metadata:
  name: health-check-job
  namespace: dns-filtering
  labels:
    app.kubernetes.io/name: final-project
    app.kubernetes.io/component: health-check
    job.kubernetes.io/name: health-check
spec:
  activeDeadlineSeconds: 600
  backoffLimit: 2
  ttlSecondsAfterFinished: 86400
  template:
    metadata:
      labels:
        app.kubernetes.io/name: final-project
        app.kubernetes.io/component: health-check
    spec:
      restartPolicy: Never
      serviceAccountName: dns-service-account
      containers:
        - name: health-check
          image: curlimages/curl:latest
          imagePullPolicy: Always
          command:
            - /bin/sh
            - -c
            - |
              echo "Checking DNS Service health..."
              curl -f -s http://final-project:80/health/live || exit 1
              echo "Checking Kafka health..."
              nc -z kafka 9092 || exit 1
              echo "Checking MariaDB health..."
              nc -z mariadb 3306 || exit 1
              echo "All services are healthy"
              exit 0
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 200m
              memory: 256Mi
---
# CronJob for Daily Health Checks
apiVersion: batch/v1
kind: CronJob
metadata:
  name: health-check-cron
  namespace: dns-filtering
  labels:
    app.kubernetes.io/name: final-project
    app.kubernetes.io/component: health-check
    job.kubernetes.io/name: health-check
spec:
  schedule: "0 * * * *"  # Every hour at minute 0
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      activeDeadlineSeconds: 600
      backoffLimit: 2
      ttlSecondsAfterFinished: 86400
      template:
        metadata:
          labels:
            app.kubernetes.io/name: final-project
            app.kubernetes.io/component: health-check
        spec:
          restartPolicy: Never
          serviceAccountName: dns-service-account
          containers:
            - name: health-check
              image: curlimages/curl:latest
              imagePullPolicy: Always
              command:
                - /bin/sh
                - -c
                - |
                  echo "Running scheduled health check..."
                  echo "Checking DNS Service health..."
                  curl -f -s http://final-project:80/health/live && echo "✓ DNS Service is healthy"
                  echo "Checking Kafka health..."
                  nc -z kafka 9092 && echo "✓ Kafka is healthy"
                  echo "Checking MariaDB health..."
                  nc -z mariadb 3306 && echo "✓ MariaDB is healthy"
                  echo "Health check completed"
              resources:
                requests:
                  cpu: 50m
                  memory: 64Mi
                limits:
                  cpu: 200m
                  memory: 256Mi
---
# CronJob for Database Backup
apiVersion: batch/v1
kind: CronJob
metadata:
  name: mariadb-backup-cron
  namespace: dns-filtering
  labels:
    app.kubernetes.io/name: mariadb
    app.kubernetes.io/component: database
    job.kubernetes.io/name: backup
spec:
  schedule: "0 2 * * *"  # Every day at 2 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      activeDeadlineSeconds: 1800
      backoffLimit: 1
      ttlSecondsAfterFinished: 604800  # 7 days
      template:
        metadata:
          labels:
            app.kubernetes.io/name: mariadb
            app.kubernetes.io/component: database
        spec:
          restartPolicy: Never
          serviceAccountName: mariadb-account
          containers:
            - name: mariadb-backup
              image: docker.io/library/mariadb:latest
              imagePullPolicy: Always
              command:
                - /bin/sh
                - -c
                - |
                  BACKUP_DIR="/backup"
                  mkdir -p $BACKUP_DIR
                  TIMESTAMP=$(date +%Y%m%d_%H%M%S)
                  BACKUP_FILE="$BACKUP_DIR/mariadb_backup_$TIMESTAMP.sql"
                  
                  echo "Starting MariaDB backup to $BACKUP_FILE..."
                  mysqldump -h mariadb -u root -p${MYSQL_ROOT_PASSWORD} --all-databases > $BACKUP_FILE
                  
                  if [ $? -eq 0 ]; then
                    echo "Backup completed successfully"
                    ls -lh $BACKUP_FILE
                  else
                    echo "Backup failed"
                    exit 1
                  fi
              env:
                - name: MYSQL_ROOT_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: mariadb-credentials
                      key: MYSQL_ROOT_PASSWORD
              resources:
                requests:
                  cpu: 200m
                  memory: 256Mi
                limits:
                  cpu: 1000m
                  memory: 1Gi
              volumeMounts:
                - name: backup-storage
                  mountPath: /backup
          volumes:
            - name: backup-storage
              emptyDir: { }
---
# CronJob for Cleanup Jobs
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cleanup-cron
  namespace: dns-filtering
  labels:
    app.kubernetes.io/name: final-project
    app.kubernetes.io/component: cleanup
    job.kubernetes.io/name: cleanup
spec:
  schedule: "0 3 * * 0"  # Every Sunday at 3 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      activeDeadlineSeconds: 600
      backoffLimit: 1
      ttlSecondsAfterFinished: 86400
      template:
        metadata:
          labels:
            app.kubernetes.io/name: final-project
            app.kubernetes.io/component: cleanup
        spec:
          restartPolicy: Never
          serviceAccountName: dns-service-account
          containers:
            - name: cleanup
              image: bitnami/kubectl:latest
              imagePullPolicy: Always
              command:
                - /bin/sh
                - -c
                - |
                  echo "Running cleanup tasks..."
                  echo "Deleting old completed jobs..."
                  kubectl delete job -n dns-filtering --field-selector status.successful=1 --sort-by=.metadata.creationTimestamp | head -n -10 || true
                  echo "Cleanup completed"
              resources:
                requests:
                  cpu: 100m
                  memory: 128Mi
                limits:
                  cpu: 500m
                  memory: 512Mi
